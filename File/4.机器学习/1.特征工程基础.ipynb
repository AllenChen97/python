{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\CDA\\File')\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "img1 = plt.imread(\"lena_cor.jpg\")\n",
    "r=img1[:,:,0]\n",
    "g=img1[:,:,1]\n",
    "b=img1[:,:,2]\n",
    "plt.figure(\"lena\")\n",
    "ar=np.array(r).flatten()\n",
    "plt.hist(ar, bins=256, density=1,facecolor='r',edgecolor='r')\n",
    "ag=np.array(g).flatten()\n",
    "plt.hist(ag, bins=256, density=1, facecolor='g',edgecolor='g')\n",
    "ab=np.array(b).flatten()\n",
    "plt.hist(ab, bins=256, density=1, facecolor='b',edgecolor='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鸢尾花数据集\n",
    "IRIS数据集由Fisher在1936年整理，包含4个特征（Sepal.Length（花萼长度）、Sepal.Width（花萼宽度）、Petal.Length（花瓣长度）、Petal.Width（花瓣宽度）），特征值都为正浮点数，单位为厘米。目标值为鸢尾花的分类（Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），Iris Virginica（维吉尼亚鸢尾））。导入IRIS数据集的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "#导入IRIS数据集\n",
    "iris = load_iris()\n",
    "#特征矩阵\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#目标向量\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target.T.shape#一维数据不分行和列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标准化 （z-分数标准化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
       "        -9.20547742e-01],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
       "        -7.88915558e-01],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
       "         5.27406285e-01],\n",
       "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
       "         1.32509732e-01],\n",
       "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
       "         2.64141916e-01],\n",
       "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
       "         1.32509732e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
       "        -1.30754636e-01],\n",
       "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
       "        -1.30754636e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
       "        -2.62386821e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
       "         8.77547895e-04],\n",
       "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
       "         5.27406285e-01],\n",
       "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
       "         5.27406285e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
       "         1.32509732e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
       "         2.64141916e-01],\n",
       "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
       "        -1.30754636e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
       "         1.71209594e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
       "         1.18556721e+00],\n",
       "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
       "         1.18556721e+00],\n",
       "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         1.05393502e+00],\n",
       "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
       "         1.44883158e+00],\n",
       "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
       "         5.27406285e-01],\n",
       "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
       "         9.22302838e-01],\n",
       "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
       "         2.64141916e-01],\n",
       "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
       "         1.18556721e+00],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
       "         1.44883158e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
       "         7.90670654e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#标准化，返回值为标准化后的数据\n",
    "StandardScaler().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 区间缩放法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#区间缩放，返回值为缩放到[0, 1]区间的数据\n",
    "MinMaxScaler().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.34313725, 0.1372549 , 0.01960784],\n",
       "       [0.51578947, 0.31578947, 0.14736842, 0.02105263],\n",
       "       [0.5       , 0.34042553, 0.13829787, 0.0212766 ],\n",
       "       [0.4893617 , 0.32978723, 0.15957447, 0.0212766 ],\n",
       "       [0.49019608, 0.35294118, 0.1372549 , 0.01960784],\n",
       "       [0.47368421, 0.34210526, 0.14912281, 0.03508772],\n",
       "       [0.4742268 , 0.35051546, 0.1443299 , 0.03092784],\n",
       "       [0.4950495 , 0.33663366, 0.14851485, 0.01980198],\n",
       "       [0.49438202, 0.3258427 , 0.15730337, 0.02247191],\n",
       "       [0.51041667, 0.32291667, 0.15625   , 0.01041667],\n",
       "       [0.5       , 0.34259259, 0.13888889, 0.01851852],\n",
       "       [0.48      , 0.34      , 0.16      , 0.02      ],\n",
       "       [0.51612903, 0.32258065, 0.15053763, 0.01075269],\n",
       "       [0.50588235, 0.35294118, 0.12941176, 0.01176471],\n",
       "       [0.51785714, 0.35714286, 0.10714286, 0.01785714],\n",
       "       [0.475     , 0.36666667, 0.125     , 0.03333333],\n",
       "       [0.49090909, 0.35454545, 0.11818182, 0.03636364],\n",
       "       [0.49514563, 0.33980583, 0.13592233, 0.02912621],\n",
       "       [0.49565217, 0.33043478, 0.14782609, 0.02608696],\n",
       "       [0.47663551, 0.35514019, 0.14018692, 0.02803738],\n",
       "       [0.5046729 , 0.31775701, 0.1588785 , 0.01869159],\n",
       "       [0.47663551, 0.34579439, 0.14018692, 0.03738318],\n",
       "       [0.4893617 , 0.38297872, 0.10638298, 0.0212766 ],\n",
       "       [0.48113208, 0.31132075, 0.16037736, 0.04716981],\n",
       "       [0.46601942, 0.33009709, 0.18446602, 0.01941748],\n",
       "       [0.51020408, 0.30612245, 0.16326531, 0.02040816],\n",
       "       [0.48076923, 0.32692308, 0.15384615, 0.03846154],\n",
       "       [0.5       , 0.33653846, 0.14423077, 0.01923077],\n",
       "       [0.50980392, 0.33333333, 0.1372549 , 0.01960784],\n",
       "       [0.48453608, 0.32989691, 0.16494845, 0.02061856],\n",
       "       [0.49484536, 0.31958763, 0.16494845, 0.02061856],\n",
       "       [0.5046729 , 0.31775701, 0.14018692, 0.03738318],\n",
       "       [0.47706422, 0.37614679, 0.13761468, 0.00917431],\n",
       "       [0.48672566, 0.37168142, 0.12389381, 0.01769912],\n",
       "       [0.50515464, 0.31958763, 0.15463918, 0.02061856],\n",
       "       [0.52083333, 0.33333333, 0.125     , 0.02083333],\n",
       "       [0.52380952, 0.33333333, 0.12380952, 0.01904762],\n",
       "       [0.49      , 0.36      , 0.14      , 0.01      ],\n",
       "       [0.49438202, 0.33707865, 0.14606742, 0.02247191],\n",
       "       [0.5       , 0.33333333, 0.14705882, 0.01960784],\n",
       "       [0.4950495 , 0.34653465, 0.12871287, 0.02970297],\n",
       "       [0.53571429, 0.27380952, 0.1547619 , 0.03571429],\n",
       "       [0.48351648, 0.35164835, 0.14285714, 0.02197802],\n",
       "       [0.46728972, 0.3271028 , 0.14953271, 0.05607477],\n",
       "       [0.45535714, 0.33928571, 0.16964286, 0.03571429],\n",
       "       [0.50526316, 0.31578947, 0.14736842, 0.03157895],\n",
       "       [0.47663551, 0.35514019, 0.14953271, 0.01869159],\n",
       "       [0.4893617 , 0.34042553, 0.14893617, 0.0212766 ],\n",
       "       [0.4953271 , 0.34579439, 0.14018692, 0.01869159],\n",
       "       [0.50505051, 0.33333333, 0.14141414, 0.02020202],\n",
       "       [0.42944785, 0.19631902, 0.28834356, 0.08588957],\n",
       "       [0.41025641, 0.20512821, 0.28846154, 0.09615385],\n",
       "       [0.42073171, 0.18902439, 0.29878049, 0.09146341],\n",
       "       [0.41984733, 0.17557252, 0.30534351, 0.09923664],\n",
       "       [0.42207792, 0.18181818, 0.2987013 , 0.0974026 ],\n",
       "       [0.3986014 , 0.1958042 , 0.31468531, 0.09090909],\n",
       "       [0.39622642, 0.20754717, 0.29559748, 0.10062893],\n",
       "       [0.42241379, 0.20689655, 0.28448276, 0.0862069 ],\n",
       "       [0.42857143, 0.18831169, 0.2987013 , 0.08441558],\n",
       "       [0.39393939, 0.20454545, 0.29545455, 0.10606061],\n",
       "       [0.43478261, 0.17391304, 0.30434783, 0.08695652],\n",
       "       [0.40410959, 0.20547945, 0.28767123, 0.10273973],\n",
       "       [0.45454545, 0.16666667, 0.3030303 , 0.07575758],\n",
       "       [0.40397351, 0.19205298, 0.31125828, 0.09271523],\n",
       "       [0.41791045, 0.21641791, 0.26865672, 0.09701493],\n",
       "       [0.42948718, 0.19871795, 0.28205128, 0.08974359],\n",
       "       [0.38356164, 0.20547945, 0.30821918, 0.10273973],\n",
       "       [0.42647059, 0.19852941, 0.30147059, 0.07352941],\n",
       "       [0.43055556, 0.15277778, 0.3125    , 0.10416667],\n",
       "       [0.42748092, 0.19083969, 0.29770992, 0.08396947],\n",
       "       [0.37579618, 0.20382166, 0.30573248, 0.11464968],\n",
       "       [0.42957746, 0.1971831 , 0.28169014, 0.0915493 ],\n",
       "       [0.41447368, 0.16447368, 0.32236842, 0.09868421],\n",
       "       [0.41216216, 0.18918919, 0.31756757, 0.08108108],\n",
       "       [0.4295302 , 0.19463087, 0.2885906 , 0.08724832],\n",
       "       [0.42857143, 0.19480519, 0.28571429, 0.09090909],\n",
       "       [0.43037975, 0.17721519, 0.30379747, 0.08860759],\n",
       "       [0.40853659, 0.18292683, 0.30487805, 0.10365854],\n",
       "       [0.40268456, 0.19463087, 0.30201342, 0.10067114],\n",
       "       [0.4453125 , 0.203125  , 0.2734375 , 0.078125  ],\n",
       "       [0.4296875 , 0.1875    , 0.296875  , 0.0859375 ],\n",
       "       [0.43650794, 0.19047619, 0.29365079, 0.07936508],\n",
       "       [0.42647059, 0.19852941, 0.28676471, 0.08823529],\n",
       "       [0.38961039, 0.17532468, 0.33116883, 0.1038961 ],\n",
       "       [0.375     , 0.20833333, 0.3125    , 0.10416667],\n",
       "       [0.38709677, 0.21935484, 0.29032258, 0.10322581],\n",
       "       [0.41875   , 0.19375   , 0.29375   , 0.09375   ],\n",
       "       [0.44055944, 0.16083916, 0.30769231, 0.09090909],\n",
       "       [0.4       , 0.21428571, 0.29285714, 0.09285714],\n",
       "       [0.41353383, 0.18796992, 0.30075188, 0.09774436],\n",
       "       [0.40145985, 0.18978102, 0.32116788, 0.08759124],\n",
       "       [0.40397351, 0.1986755 , 0.30463576, 0.09271523],\n",
       "       [0.42647059, 0.19117647, 0.29411765, 0.08823529],\n",
       "       [0.43103448, 0.19827586, 0.28448276, 0.0862069 ],\n",
       "       [0.4057971 , 0.19565217, 0.30434783, 0.0942029 ],\n",
       "       [0.40425532, 0.21276596, 0.29787234, 0.08510638],\n",
       "       [0.40425532, 0.20567376, 0.29787234, 0.09219858],\n",
       "       [0.42176871, 0.19727891, 0.29251701, 0.08843537],\n",
       "       [0.43589744, 0.21367521, 0.25641026, 0.09401709],\n",
       "       [0.41007194, 0.20143885, 0.29496403, 0.09352518],\n",
       "       [0.3480663 , 0.18232044, 0.33149171, 0.13812155],\n",
       "       [0.37419355, 0.17419355, 0.32903226, 0.12258065],\n",
       "       [0.39226519, 0.16574586, 0.32596685, 0.1160221 ],\n",
       "       [0.37951807, 0.1746988 , 0.3373494 , 0.10843373],\n",
       "       [0.37142857, 0.17142857, 0.33142857, 0.12571429],\n",
       "       [0.39378238, 0.15544041, 0.34196891, 0.10880829],\n",
       "       [0.36029412, 0.18382353, 0.33088235, 0.125     ],\n",
       "       [0.3989071 , 0.15846995, 0.3442623 , 0.09836066],\n",
       "       [0.39880952, 0.14880952, 0.3452381 , 0.10714286],\n",
       "       [0.37113402, 0.18556701, 0.31443299, 0.12886598],\n",
       "       [0.38690476, 0.19047619, 0.30357143, 0.11904762],\n",
       "       [0.39263804, 0.16564417, 0.32515337, 0.11656442],\n",
       "       [0.3908046 , 0.17241379, 0.31609195, 0.12068966],\n",
       "       [0.375     , 0.16447368, 0.32894737, 0.13157895],\n",
       "       [0.36024845, 0.17391304, 0.31677019, 0.14906832],\n",
       "       [0.37209302, 0.18604651, 0.30813953, 0.13372093],\n",
       "       [0.38690476, 0.17857143, 0.32738095, 0.10714286],\n",
       "       [0.37745098, 0.18627451, 0.32843137, 0.10784314],\n",
       "       [0.39487179, 0.13333333, 0.35384615, 0.11794872],\n",
       "       [0.40816327, 0.14965986, 0.34013605, 0.10204082],\n",
       "       [0.38121547, 0.17679558, 0.31491713, 0.12707182],\n",
       "       [0.36601307, 0.18300654, 0.32026144, 0.13071895],\n",
       "       [0.40104167, 0.14583333, 0.34895833, 0.10416667],\n",
       "       [0.40127389, 0.17197452, 0.31210191, 0.11464968],\n",
       "       [0.37640449, 0.18539326, 0.32022472, 0.11797753],\n",
       "       [0.3956044 , 0.17582418, 0.32967033, 0.0989011 ],\n",
       "       [0.3974359 , 0.17948718, 0.30769231, 0.11538462],\n",
       "       [0.38607595, 0.18987342, 0.31012658, 0.11392405],\n",
       "       [0.37869822, 0.16568047, 0.33136095, 0.12426036],\n",
       "       [0.40909091, 0.17045455, 0.32954545, 0.09090909],\n",
       "       [0.40659341, 0.15384615, 0.33516484, 0.1043956 ],\n",
       "       [0.39303483, 0.18905473, 0.31840796, 0.09950249],\n",
       "       [0.37647059, 0.16470588, 0.32941176, 0.12941176],\n",
       "       [0.40127389, 0.17834395, 0.32484076, 0.0955414 ],\n",
       "       [0.38853503, 0.1656051 , 0.3566879 , 0.08917197],\n",
       "       [0.40314136, 0.15706806, 0.31937173, 0.12041885],\n",
       "       [0.3559322 , 0.1920904 , 0.31638418, 0.13559322],\n",
       "       [0.38095238, 0.18452381, 0.32738095, 0.10714286],\n",
       "       [0.38461538, 0.19230769, 0.30769231, 0.11538462],\n",
       "       [0.39428571, 0.17714286, 0.30857143, 0.12      ],\n",
       "       [0.37640449, 0.1741573 , 0.31460674, 0.13483146],\n",
       "       [0.39655172, 0.17816092, 0.29310345, 0.13218391],\n",
       "       [0.37419355, 0.17419355, 0.32903226, 0.12258065],\n",
       "       [0.37362637, 0.17582418, 0.32417582, 0.12637363],\n",
       "       [0.36813187, 0.18131868, 0.31318681, 0.13736264],\n",
       "       [0.38953488, 0.1744186 , 0.30232558, 0.13372093],\n",
       "       [0.40127389, 0.15923567, 0.31847134, 0.12101911],\n",
       "       [0.38922156, 0.17964072, 0.31137725, 0.11976048],\n",
       "       [0.3583815 , 0.19653179, 0.31213873, 0.13294798],\n",
       "       [0.37341772, 0.18987342, 0.32278481, 0.11392405]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "Normalizer(norm='l1').fit_transform(iris.data)#默认为l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Normalizer in module sklearn.preprocessing.data:\n",
      "\n",
      "class Normalizer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Normalizer(norm='l2', copy=True)\n",
      " |  \n",
      " |  Normalize samples individually to unit norm.\n",
      " |  \n",
      " |  Each sample (i.e. each row of the data matrix) with at least one\n",
      " |  non zero component is rescaled independently of other samples so\n",
      " |  that its norm (l1 or l2) equals one.\n",
      " |  \n",
      " |  This transformer is able to work both with dense numpy arrays and\n",
      " |  scipy.sparse matrix (use CSR format if you want to avoid the burden of\n",
      " |  a copy / conversion).\n",
      " |  \n",
      " |  Scaling inputs to unit norms is a common operation for text\n",
      " |  classification or clustering for instance. For instance the dot\n",
      " |  product of two l2-normalized TF-IDF vectors is the cosine similarity\n",
      " |  of the vectors and is the base similarity metric for the Vector\n",
      " |  Space Model commonly used by the Information Retrieval community.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_normalization>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  norm : 'l1', 'l2', or 'max', optional ('l2' by default)\n",
      " |      The norm to use to normalize each non zero sample.\n",
      " |  \n",
      " |  copy : boolean, optional, default True\n",
      " |      set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array or a scipy.sparse\n",
      " |      CSR matrix).\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import Normalizer\n",
      " |  >>> X = [[4, 1, 2, 2],\n",
      " |  ...      [1, 3, 9, 3],\n",
      " |  ...      [5, 7, 5, 1]]\n",
      " |  >>> transformer = Normalizer().fit(X) # fit does nothing.\n",
      " |  >>> transformer\n",
      " |  Normalizer(copy=True, norm='l2')\n",
      " |  >>> transformer.transform(X)\n",
      " |  array([[0.8, 0.2, 0.4, 0.4],\n",
      " |         [0.1, 0.3, 0.9, 0.3],\n",
      " |         [0.5, 0.7, 0.5, 0.1]])\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  This estimator is stateless (besides constructor parameters), the\n",
      " |  fit method does nothing but is useful when used in a pipeline.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  normalize: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Normalizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, norm='l2', copy=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Do nothing and return the estimator unchanged\n",
      " |      \n",
      " |      This method is just there to implement the usual API and hence\n",
      " |      work in pipelines.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like\n",
      " |  \n",
      " |  transform(self, X, y='deprecated', copy=None)\n",
      " |      Scale each non zero row of X to unit norm\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data to normalize, row by row. scipy.sparse matrices should be\n",
      " |          in CSR format to avoid an un-necessary copy.\n",
      " |      y : (ignored)\n",
      " |          .. deprecated:: 0.19\n",
      " |             This parameter will be removed in 0.21.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "#二值化，阈值设置为3，返回值为二值化后的数据\n",
    "Binarizer(threshold=3).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder().fit([1,111,122,188,999])#0,1,2,3,4\n",
    "le_transform = le.transform([999,122,111])\n",
    "print(le_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 哑编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._encoders.OneHotEncoder"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.preprocessing.OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#哑编码\n",
    "list1=[[1, 1, 4], [2, 2, 1], [1, 3, 2], [2, 1, 3]]\n",
    "OneHotEncoder().fit_transform(list1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  5.1 ,  3.5 , ...,  1.96,  0.28,  0.04],\n",
       "       [ 1.  ,  4.9 ,  3.  , ...,  1.96,  0.28,  0.04],\n",
       "       [ 1.  ,  4.7 ,  3.2 , ...,  1.69,  0.26,  0.04],\n",
       "       ...,\n",
       "       [ 1.  ,  6.5 ,  3.  , ..., 27.04, 10.4 ,  4.  ],\n",
       "       [ 1.  ,  6.2 ,  3.4 , ..., 29.16, 12.42,  5.29],\n",
       "       [ 1.  ,  5.9 ,  3.  , ..., 26.01,  9.18,  3.24]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#多项式转换\n",
    "#参数degree为度，默认值为2\n",
    "PolynomialFeatures().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PolynomialFeatures in module sklearn.preprocessing.data:\n",
      "\n",
      "class PolynomialFeatures(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
      " |  \n",
      " |  Generate polynomial and interaction features.\n",
      " |  \n",
      " |  Generate a new feature matrix consisting of all polynomial combinations\n",
      " |  of the features with degree less than or equal to the specified degree.\n",
      " |  For example, if an input sample is two dimensional and of the form\n",
      " |  [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  degree : integer\n",
      " |      The degree of the polynomial features. Default = 2.\n",
      " |  \n",
      " |  interaction_only : boolean, default = False\n",
      " |      If true, only interaction features are produced: features that are\n",
      " |      products of at most ``degree`` *distinct* input features (so not\n",
      " |      ``x[1] ** 2``, ``x[0] * x[2] ** 3``, etc.).\n",
      " |  \n",
      " |  include_bias : boolean\n",
      " |      If True (default), then include a bias column, the feature in which\n",
      " |      all polynomial powers are zero (i.e. a column of ones - acts as an\n",
      " |      intercept term in a linear model).\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = np.arange(6).reshape(3, 2)\n",
      " |  >>> X\n",
      " |  array([[0, 1],\n",
      " |         [2, 3],\n",
      " |         [4, 5]])\n",
      " |  >>> poly = PolynomialFeatures(2)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
      " |         [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
      " |         [ 1.,  4.,  5., 16., 20., 25.]])\n",
      " |  >>> poly = PolynomialFeatures(interaction_only=True)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.],\n",
      " |         [ 1.,  2.,  3.,  6.],\n",
      " |         [ 1.,  4.,  5., 20.]])\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  powers_ : array, shape (n_output_features, n_input_features)\n",
      " |      powers_[i, j] is the exponent of the jth input in the ith output.\n",
      " |  \n",
      " |  n_input_features_ : int\n",
      " |      The total number of input features.\n",
      " |  \n",
      " |  n_output_features_ : int\n",
      " |      The total number of polynomial output features. The number of output\n",
      " |      features is computed by iterating over all suitably sized combinations\n",
      " |      of input features.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Be aware that the number of features in the output array scales\n",
      " |  polynomially in the number of features of the input array, and\n",
      " |  exponentially in the degree. High degrees can cause overfitting.\n",
      " |  \n",
      " |  See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
      " |  <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PolynomialFeatures\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, degree=2, interaction_only=False, include_bias=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute number of output features.\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : instance\n",
      " |  \n",
      " |  get_feature_names(self, input_features=None)\n",
      " |      Return feature names for output features\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : list of string, length n_features, optional\n",
      " |          String names for input features if available. By default,\n",
      " |          \"x0\", \"x1\", ... \"xn_features\" is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      output_feature_names : list of string, length n_output_features\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform data to polynomial features\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape [n_samples, n_features]\n",
      " |          The data to transform, row by row.\n",
      " |          Sparse input should preferably be in CSC format.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      XP : np.ndarray or CSC sparse matrix, shape [n_samples, NP]\n",
      " |          The matrix of features, where NP is the number of polynomial\n",
      " |          features generated from the combination of inputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  powers_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PolynomialFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "D:\\conda\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.80828877, 1.5040774 , 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.38629436, 0.87546874, 0.18232156],\n",
       "       [1.74046617, 1.43508453, 0.83290912, 0.18232156],\n",
       "       [1.7227666 , 1.41098697, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.5260563 , 0.87546874, 0.18232156],\n",
       "       [1.85629799, 1.58923521, 0.99325177, 0.33647224],\n",
       "       [1.7227666 , 1.48160454, 0.87546874, 0.26236426],\n",
       "       [1.79175947, 1.48160454, 0.91629073, 0.18232156],\n",
       "       [1.68639895, 1.36097655, 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.41098697, 0.91629073, 0.09531018],\n",
       "       [1.85629799, 1.54756251, 0.91629073, 0.18232156],\n",
       "       [1.75785792, 1.48160454, 0.95551145, 0.18232156],\n",
       "       [1.75785792, 1.38629436, 0.87546874, 0.09531018],\n",
       "       [1.66770682, 1.38629436, 0.74193734, 0.09531018],\n",
       "       [1.91692261, 1.60943791, 0.78845736, 0.18232156],\n",
       "       [1.90210753, 1.68639895, 0.91629073, 0.33647224],\n",
       "       [1.85629799, 1.58923521, 0.83290912, 0.33647224],\n",
       "       [1.80828877, 1.5040774 , 0.87546874, 0.26236426],\n",
       "       [1.90210753, 1.56861592, 0.99325177, 0.26236426],\n",
       "       [1.80828877, 1.56861592, 0.91629073, 0.26236426],\n",
       "       [1.85629799, 1.48160454, 0.99325177, 0.18232156],\n",
       "       [1.80828877, 1.54756251, 0.91629073, 0.33647224],\n",
       "       [1.7227666 , 1.5260563 , 0.69314718, 0.18232156],\n",
       "       [1.80828877, 1.45861502, 0.99325177, 0.40546511],\n",
       "       [1.75785792, 1.48160454, 1.06471074, 0.18232156],\n",
       "       [1.79175947, 1.38629436, 0.95551145, 0.18232156],\n",
       "       [1.79175947, 1.48160454, 0.95551145, 0.33647224],\n",
       "       [1.82454929, 1.5040774 , 0.91629073, 0.18232156],\n",
       "       [1.82454929, 1.48160454, 0.87546874, 0.18232156],\n",
       "       [1.74046617, 1.43508453, 0.95551145, 0.18232156],\n",
       "       [1.75785792, 1.41098697, 0.95551145, 0.18232156],\n",
       "       [1.85629799, 1.48160454, 0.91629073, 0.33647224],\n",
       "       [1.82454929, 1.62924054, 0.91629073, 0.09531018],\n",
       "       [1.87180218, 1.64865863, 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.41098697, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.43508453, 0.78845736, 0.18232156],\n",
       "       [1.87180218, 1.5040774 , 0.83290912, 0.18232156],\n",
       "       [1.77495235, 1.5260563 , 0.87546874, 0.09531018],\n",
       "       [1.68639895, 1.38629436, 0.83290912, 0.18232156],\n",
       "       [1.80828877, 1.48160454, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.5040774 , 0.83290912, 0.26236426],\n",
       "       [1.70474809, 1.19392247, 0.83290912, 0.26236426],\n",
       "       [1.68639895, 1.43508453, 0.83290912, 0.18232156],\n",
       "       [1.79175947, 1.5040774 , 0.95551145, 0.47000363],\n",
       "       [1.80828877, 1.56861592, 1.06471074, 0.33647224],\n",
       "       [1.75785792, 1.38629436, 0.87546874, 0.26236426],\n",
       "       [1.80828877, 1.56861592, 0.95551145, 0.18232156],\n",
       "       [1.7227666 , 1.43508453, 0.87546874, 0.18232156],\n",
       "       [1.84054963, 1.54756251, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.45861502, 0.87546874, 0.18232156],\n",
       "       [2.07944154, 1.43508453, 1.74046617, 0.87546874],\n",
       "       [2.00148   , 1.43508453, 1.70474809, 0.91629073],\n",
       "       [2.06686276, 1.41098697, 1.77495235, 0.91629073],\n",
       "       [1.87180218, 1.19392247, 1.60943791, 0.83290912],\n",
       "       [2.01490302, 1.33500107, 1.7227666 , 0.91629073],\n",
       "       [1.90210753, 1.33500107, 1.70474809, 0.83290912],\n",
       "       [1.98787435, 1.45861502, 1.74046617, 0.95551145],\n",
       "       [1.77495235, 1.22377543, 1.45861502, 0.69314718],\n",
       "       [2.02814825, 1.36097655, 1.7227666 , 0.83290912],\n",
       "       [1.82454929, 1.30833282, 1.58923521, 0.87546874],\n",
       "       [1.79175947, 1.09861229, 1.5040774 , 0.69314718],\n",
       "       [1.93152141, 1.38629436, 1.64865863, 0.91629073],\n",
       "       [1.94591015, 1.16315081, 1.60943791, 0.69314718],\n",
       "       [1.96009478, 1.36097655, 1.74046617, 0.87546874],\n",
       "       [1.88706965, 1.36097655, 1.5260563 , 0.83290912],\n",
       "       [2.04122033, 1.41098697, 1.68639895, 0.87546874],\n",
       "       [1.88706965, 1.38629436, 1.70474809, 0.91629073],\n",
       "       [1.91692261, 1.30833282, 1.62924054, 0.69314718],\n",
       "       [1.97408103, 1.16315081, 1.70474809, 0.91629073],\n",
       "       [1.88706965, 1.25276297, 1.58923521, 0.74193734],\n",
       "       [1.93152141, 1.43508453, 1.75785792, 1.02961942],\n",
       "       [1.96009478, 1.33500107, 1.60943791, 0.83290912],\n",
       "       [1.98787435, 1.25276297, 1.77495235, 0.91629073],\n",
       "       [1.96009478, 1.33500107, 1.74046617, 0.78845736],\n",
       "       [2.00148   , 1.36097655, 1.66770682, 0.83290912],\n",
       "       [2.02814825, 1.38629436, 1.68639895, 0.87546874],\n",
       "       [2.05412373, 1.33500107, 1.75785792, 0.87546874],\n",
       "       [2.04122033, 1.38629436, 1.79175947, 0.99325177],\n",
       "       [1.94591015, 1.36097655, 1.70474809, 0.91629073],\n",
       "       [1.90210753, 1.28093385, 1.5040774 , 0.69314718],\n",
       "       [1.87180218, 1.22377543, 1.56861592, 0.74193734],\n",
       "       [1.87180218, 1.22377543, 1.54756251, 0.69314718],\n",
       "       [1.91692261, 1.30833282, 1.58923521, 0.78845736],\n",
       "       [1.94591015, 1.30833282, 1.80828877, 0.95551145],\n",
       "       [1.85629799, 1.38629436, 1.70474809, 0.91629073],\n",
       "       [1.94591015, 1.48160454, 1.70474809, 0.95551145],\n",
       "       [2.04122033, 1.41098697, 1.74046617, 0.91629073],\n",
       "       [1.98787435, 1.19392247, 1.68639895, 0.83290912],\n",
       "       [1.88706965, 1.38629436, 1.62924054, 0.83290912],\n",
       "       [1.87180218, 1.25276297, 1.60943791, 0.83290912],\n",
       "       [1.87180218, 1.28093385, 1.68639895, 0.78845736],\n",
       "       [1.96009478, 1.38629436, 1.7227666 , 0.87546874],\n",
       "       [1.91692261, 1.28093385, 1.60943791, 0.78845736],\n",
       "       [1.79175947, 1.19392247, 1.45861502, 0.69314718],\n",
       "       [1.88706965, 1.30833282, 1.64865863, 0.83290912],\n",
       "       [1.90210753, 1.38629436, 1.64865863, 0.78845736],\n",
       "       [1.90210753, 1.36097655, 1.64865863, 0.83290912],\n",
       "       [1.97408103, 1.36097655, 1.66770682, 0.83290912],\n",
       "       [1.80828877, 1.25276297, 1.38629436, 0.74193734],\n",
       "       [1.90210753, 1.33500107, 1.62924054, 0.83290912],\n",
       "       [1.98787435, 1.45861502, 1.94591015, 1.25276297],\n",
       "       [1.91692261, 1.30833282, 1.80828877, 1.06471074],\n",
       "       [2.09186406, 1.38629436, 1.93152141, 1.13140211],\n",
       "       [1.98787435, 1.36097655, 1.88706965, 1.02961942],\n",
       "       [2.01490302, 1.38629436, 1.91692261, 1.16315081],\n",
       "       [2.1517622 , 1.38629436, 2.02814825, 1.13140211],\n",
       "       [1.77495235, 1.25276297, 1.70474809, 0.99325177],\n",
       "       [2.11625551, 1.36097655, 1.98787435, 1.02961942],\n",
       "       [2.04122033, 1.25276297, 1.91692261, 1.02961942],\n",
       "       [2.10413415, 1.5260563 , 1.96009478, 1.25276297],\n",
       "       [2.01490302, 1.43508453, 1.80828877, 1.09861229],\n",
       "       [2.00148   , 1.30833282, 1.84054963, 1.06471074],\n",
       "       [2.05412373, 1.38629436, 1.87180218, 1.13140211],\n",
       "       [1.90210753, 1.25276297, 1.79175947, 1.09861229],\n",
       "       [1.91692261, 1.33500107, 1.80828877, 1.22377543],\n",
       "       [2.00148   , 1.43508453, 1.84054963, 1.19392247],\n",
       "       [2.01490302, 1.38629436, 1.87180218, 1.02961942],\n",
       "       [2.16332303, 1.56861592, 2.04122033, 1.16315081],\n",
       "       [2.16332303, 1.28093385, 2.06686276, 1.19392247],\n",
       "       [1.94591015, 1.16315081, 1.79175947, 0.91629073],\n",
       "       [2.06686276, 1.43508453, 1.90210753, 1.19392247],\n",
       "       [1.88706965, 1.33500107, 1.77495235, 1.09861229],\n",
       "       [2.16332303, 1.33500107, 2.04122033, 1.09861229],\n",
       "       [1.98787435, 1.30833282, 1.77495235, 1.02961942],\n",
       "       [2.04122033, 1.45861502, 1.90210753, 1.13140211],\n",
       "       [2.10413415, 1.43508453, 1.94591015, 1.02961942],\n",
       "       [1.97408103, 1.33500107, 1.75785792, 1.02961942],\n",
       "       [1.96009478, 1.38629436, 1.77495235, 1.02961942],\n",
       "       [2.00148   , 1.33500107, 1.88706965, 1.13140211],\n",
       "       [2.10413415, 1.38629436, 1.91692261, 0.95551145],\n",
       "       [2.12823171, 1.33500107, 1.96009478, 1.06471074],\n",
       "       [2.18605128, 1.56861592, 2.00148   , 1.09861229],\n",
       "       [2.00148   , 1.33500107, 1.88706965, 1.16315081],\n",
       "       [1.98787435, 1.33500107, 1.80828877, 0.91629073],\n",
       "       [1.96009478, 1.28093385, 1.88706965, 0.87546874],\n",
       "       [2.16332303, 1.38629436, 1.96009478, 1.19392247],\n",
       "       [1.98787435, 1.48160454, 1.88706965, 1.22377543],\n",
       "       [2.00148   , 1.41098697, 1.87180218, 1.02961942],\n",
       "       [1.94591015, 1.38629436, 1.75785792, 1.02961942],\n",
       "       [2.06686276, 1.41098697, 1.85629799, 1.13140211],\n",
       "       [2.04122033, 1.41098697, 1.88706965, 1.22377543],\n",
       "       [2.06686276, 1.41098697, 1.80828877, 1.19392247],\n",
       "       [1.91692261, 1.30833282, 1.80828877, 1.06471074],\n",
       "       [2.05412373, 1.43508453, 1.93152141, 1.19392247],\n",
       "       [2.04122033, 1.45861502, 1.90210753, 1.25276297],\n",
       "       [2.04122033, 1.38629436, 1.82454929, 1.19392247],\n",
       "       [1.98787435, 1.25276297, 1.79175947, 1.06471074],\n",
       "       [2.01490302, 1.38629436, 1.82454929, 1.09861229],\n",
       "       [1.97408103, 1.48160454, 1.85629799, 1.19392247],\n",
       "       [1.93152141, 1.38629436, 1.80828877, 1.02961942]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对数变换\n",
    "from numpy import log1p\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#自定义转换函数为对数函数的数据变换\n",
    "#第一个参数是单变元函数\n",
    "FunctionTransformer(log1p).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68412563,  0.31939725],\n",
       "       [-2.71414169, -0.17700123],\n",
       "       [-2.88899057, -0.14494943],\n",
       "       [-2.74534286, -0.31829898],\n",
       "       [-2.72871654,  0.32675451],\n",
       "       [-2.28085963,  0.74133045],\n",
       "       [-2.82053775, -0.08946138],\n",
       "       [-2.62614497,  0.16338496],\n",
       "       [-2.88638273, -0.57831175],\n",
       "       [-2.6727558 , -0.11377425],\n",
       "       [-2.50694709,  0.6450689 ],\n",
       "       [-2.61275523,  0.01472994],\n",
       "       [-2.78610927, -0.235112  ],\n",
       "       [-3.22380374, -0.51139459],\n",
       "       [-2.64475039,  1.17876464],\n",
       "       [-2.38603903,  1.33806233],\n",
       "       [-2.62352788,  0.81067951],\n",
       "       [-2.64829671,  0.31184914],\n",
       "       [-2.19982032,  0.87283904],\n",
       "       [-2.5879864 ,  0.51356031],\n",
       "       [-2.31025622,  0.39134594],\n",
       "       [-2.54370523,  0.43299606],\n",
       "       [-3.21593942,  0.13346807],\n",
       "       [-2.30273318,  0.09870885],\n",
       "       [-2.35575405, -0.03728186],\n",
       "       [-2.50666891, -0.14601688],\n",
       "       [-2.46882007,  0.13095149],\n",
       "       [-2.56231991,  0.36771886],\n",
       "       [-2.63953472,  0.31203998],\n",
       "       [-2.63198939, -0.19696122],\n",
       "       [-2.58739848, -0.20431849],\n",
       "       [-2.4099325 ,  0.41092426],\n",
       "       [-2.64886233,  0.81336382],\n",
       "       [-2.59873675,  1.09314576],\n",
       "       [-2.63692688, -0.12132235],\n",
       "       [-2.86624165,  0.06936447],\n",
       "       [-2.62523805,  0.59937002],\n",
       "       [-2.80068412,  0.26864374],\n",
       "       [-2.98050204, -0.48795834],\n",
       "       [-2.59000631,  0.22904384],\n",
       "       [-2.77010243,  0.26352753],\n",
       "       [-2.84936871, -0.94096057],\n",
       "       [-2.99740655, -0.34192606],\n",
       "       [-2.40561449,  0.18887143],\n",
       "       [-2.20948924,  0.43666314],\n",
       "       [-2.71445143, -0.2502082 ],\n",
       "       [-2.53814826,  0.50377114],\n",
       "       [-2.83946217, -0.22794557],\n",
       "       [-2.54308575,  0.57941002],\n",
       "       [-2.70335978,  0.10770608],\n",
       "       [ 1.28482569,  0.68516047],\n",
       "       [ 0.93248853,  0.31833364],\n",
       "       [ 1.46430232,  0.50426282],\n",
       "       [ 0.18331772, -0.82795901],\n",
       "       [ 1.08810326,  0.07459068],\n",
       "       [ 0.64166908, -0.41824687],\n",
       "       [ 1.09506066,  0.28346827],\n",
       "       [-0.74912267, -1.00489096],\n",
       "       [ 1.04413183,  0.2283619 ],\n",
       "       [-0.0087454 , -0.72308191],\n",
       "       [-0.50784088, -1.26597119],\n",
       "       [ 0.51169856, -0.10398124],\n",
       "       [ 0.26497651, -0.55003646],\n",
       "       [ 0.98493451, -0.12481785],\n",
       "       [-0.17392537, -0.25485421],\n",
       "       [ 0.92786078,  0.46717949],\n",
       "       [ 0.66028376, -0.35296967],\n",
       "       [ 0.23610499, -0.33361077],\n",
       "       [ 0.94473373, -0.54314555],\n",
       "       [ 0.04522698, -0.58383438],\n",
       "       [ 1.11628318, -0.08461685],\n",
       "       [ 0.35788842, -0.06892503],\n",
       "       [ 1.29818388, -0.32778731],\n",
       "       [ 0.92172892, -0.18273779],\n",
       "       [ 0.71485333,  0.14905594],\n",
       "       [ 0.90017437,  0.32850447],\n",
       "       [ 1.33202444,  0.24444088],\n",
       "       [ 1.55780216,  0.26749545],\n",
       "       [ 0.81329065, -0.1633503 ],\n",
       "       [-0.30558378, -0.36826219],\n",
       "       [-0.06812649, -0.70517213],\n",
       "       [-0.18962247, -0.68028676],\n",
       "       [ 0.13642871, -0.31403244],\n",
       "       [ 1.38002644, -0.42095429],\n",
       "       [ 0.58800644, -0.48428742],\n",
       "       [ 0.80685831,  0.19418231],\n",
       "       [ 1.22069088,  0.40761959],\n",
       "       [ 0.81509524, -0.37203706],\n",
       "       [ 0.24595768, -0.2685244 ],\n",
       "       [ 0.16641322, -0.68192672],\n",
       "       [ 0.46480029, -0.67071154],\n",
       "       [ 0.8908152 , -0.03446444],\n",
       "       [ 0.23054802, -0.40438585],\n",
       "       [-0.70453176, -1.01224823],\n",
       "       [ 0.35698149, -0.50491009],\n",
       "       [ 0.33193448, -0.21265468],\n",
       "       [ 0.37621565, -0.29321893],\n",
       "       [ 0.64257601,  0.01773819],\n",
       "       [-0.90646986, -0.75609337],\n",
       "       [ 0.29900084, -0.34889781],\n",
       "       [ 2.53119273, -0.00984911],\n",
       "       [ 1.41523588, -0.57491635],\n",
       "       [ 2.61667602,  0.34390315],\n",
       "       [ 1.97153105, -0.1797279 ],\n",
       "       [ 2.35000592, -0.04026095],\n",
       "       [ 3.39703874,  0.55083667],\n",
       "       [ 0.52123224, -1.19275873],\n",
       "       [ 2.93258707,  0.3555    ],\n",
       "       [ 2.32122882, -0.2438315 ],\n",
       "       [ 2.91675097,  0.78279195],\n",
       "       [ 1.66177415,  0.24222841],\n",
       "       [ 1.80340195, -0.21563762],\n",
       "       [ 2.1655918 ,  0.21627559],\n",
       "       [ 1.34616358, -0.77681835],\n",
       "       [ 1.58592822, -0.53964071],\n",
       "       [ 1.90445637,  0.11925069],\n",
       "       [ 1.94968906,  0.04194326],\n",
       "       [ 3.48705536,  1.17573933],\n",
       "       [ 3.79564542,  0.25732297],\n",
       "       [ 1.30079171, -0.76114964],\n",
       "       [ 2.42781791,  0.37819601],\n",
       "       [ 1.19900111, -0.60609153],\n",
       "       [ 3.49992004,  0.4606741 ],\n",
       "       [ 1.38876613, -0.20439933],\n",
       "       [ 2.2754305 ,  0.33499061],\n",
       "       [ 2.61409047,  0.56090136],\n",
       "       [ 1.25850816, -0.17970479],\n",
       "       [ 1.29113206, -0.11666865],\n",
       "       [ 2.12360872, -0.20972948],\n",
       "       [ 2.38800302,  0.4646398 ],\n",
       "       [ 2.84167278,  0.37526917],\n",
       "       [ 3.23067366,  1.37416509],\n",
       "       [ 2.15943764, -0.21727758],\n",
       "       [ 1.44416124, -0.14341341],\n",
       "       [ 1.78129481, -0.49990168],\n",
       "       [ 3.07649993,  0.68808568],\n",
       "       [ 2.14424331,  0.1400642 ],\n",
       "       [ 1.90509815,  0.04930053],\n",
       "       [ 1.16932634, -0.16499026],\n",
       "       [ 2.10761114,  0.37228787],\n",
       "       [ 2.31415471,  0.18365128],\n",
       "       [ 1.9222678 ,  0.40920347],\n",
       "       [ 1.41523588, -0.57491635],\n",
       "       [ 2.56301338,  0.2778626 ],\n",
       "       [ 2.41874618,  0.3047982 ],\n",
       "       [ 1.94410979,  0.1875323 ],\n",
       "       [ 1.52716661, -0.37531698],\n",
       "       [ 1.76434572,  0.07885885],\n",
       "       [ 1.90094161,  0.11662796],\n",
       "       [ 1.39018886, -0.28266094]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA降维\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(iris.data)\n",
    "X_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lda降维,有监督\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_r2=lda.fit_transform(iris.data, iris.target)\n",
    "X_r2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter-1.方差选择法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2],\n",
       "       [4.6, 1.5, 0.2],\n",
       "       [5. , 1.4, 0.2],\n",
       "       [5.4, 1.7, 0.4],\n",
       "       [4.6, 1.4, 0.3],\n",
       "       [5. , 1.5, 0.2],\n",
       "       [4.4, 1.4, 0.2],\n",
       "       [4.9, 1.5, 0.1],\n",
       "       [5.4, 1.5, 0.2],\n",
       "       [4.8, 1.6, 0.2],\n",
       "       [4.8, 1.4, 0.1],\n",
       "       [4.3, 1.1, 0.1],\n",
       "       [5.8, 1.2, 0.2],\n",
       "       [5.7, 1.5, 0.4],\n",
       "       [5.4, 1.3, 0.4],\n",
       "       [5.1, 1.4, 0.3],\n",
       "       [5.7, 1.7, 0.3],\n",
       "       [5.1, 1.5, 0.3],\n",
       "       [5.4, 1.7, 0.2],\n",
       "       [5.1, 1.5, 0.4],\n",
       "       [4.6, 1. , 0.2],\n",
       "       [5.1, 1.7, 0.5],\n",
       "       [4.8, 1.9, 0.2],\n",
       "       [5. , 1.6, 0.2],\n",
       "       [5. , 1.6, 0.4],\n",
       "       [5.2, 1.5, 0.2],\n",
       "       [5.2, 1.4, 0.2],\n",
       "       [4.7, 1.6, 0.2],\n",
       "       [4.8, 1.6, 0.2],\n",
       "       [5.4, 1.5, 0.4],\n",
       "       [5.2, 1.5, 0.1],\n",
       "       [5.5, 1.4, 0.2],\n",
       "       [4.9, 1.5, 0.2],\n",
       "       [5. , 1.2, 0.2],\n",
       "       [5.5, 1.3, 0.2],\n",
       "       [4.9, 1.4, 0.1],\n",
       "       [4.4, 1.3, 0.2],\n",
       "       [5.1, 1.5, 0.2],\n",
       "       [5. , 1.3, 0.3],\n",
       "       [4.5, 1.3, 0.3],\n",
       "       [4.4, 1.3, 0.2],\n",
       "       [5. , 1.6, 0.6],\n",
       "       [5.1, 1.9, 0.4],\n",
       "       [4.8, 1.4, 0.3],\n",
       "       [5.1, 1.6, 0.2],\n",
       "       [4.6, 1.4, 0.2],\n",
       "       [5.3, 1.5, 0.2],\n",
       "       [5. , 1.4, 0.2],\n",
       "       [7. , 4.7, 1.4],\n",
       "       [6.4, 4.5, 1.5],\n",
       "       [6.9, 4.9, 1.5],\n",
       "       [5.5, 4. , 1.3],\n",
       "       [6.5, 4.6, 1.5],\n",
       "       [5.7, 4.5, 1.3],\n",
       "       [6.3, 4.7, 1.6],\n",
       "       [4.9, 3.3, 1. ],\n",
       "       [6.6, 4.6, 1.3],\n",
       "       [5.2, 3.9, 1.4],\n",
       "       [5. , 3.5, 1. ],\n",
       "       [5.9, 4.2, 1.5],\n",
       "       [6. , 4. , 1. ],\n",
       "       [6.1, 4.7, 1.4],\n",
       "       [5.6, 3.6, 1.3],\n",
       "       [6.7, 4.4, 1.4],\n",
       "       [5.6, 4.5, 1.5],\n",
       "       [5.8, 4.1, 1. ],\n",
       "       [6.2, 4.5, 1.5],\n",
       "       [5.6, 3.9, 1.1],\n",
       "       [5.9, 4.8, 1.8],\n",
       "       [6.1, 4. , 1.3],\n",
       "       [6.3, 4.9, 1.5],\n",
       "       [6.1, 4.7, 1.2],\n",
       "       [6.4, 4.3, 1.3],\n",
       "       [6.6, 4.4, 1.4],\n",
       "       [6.8, 4.8, 1.4],\n",
       "       [6.7, 5. , 1.7],\n",
       "       [6. , 4.5, 1.5],\n",
       "       [5.7, 3.5, 1. ],\n",
       "       [5.5, 3.8, 1.1],\n",
       "       [5.5, 3.7, 1. ],\n",
       "       [5.8, 3.9, 1.2],\n",
       "       [6. , 5.1, 1.6],\n",
       "       [5.4, 4.5, 1.5],\n",
       "       [6. , 4.5, 1.6],\n",
       "       [6.7, 4.7, 1.5],\n",
       "       [6.3, 4.4, 1.3],\n",
       "       [5.6, 4.1, 1.3],\n",
       "       [5.5, 4. , 1.3],\n",
       "       [5.5, 4.4, 1.2],\n",
       "       [6.1, 4.6, 1.4],\n",
       "       [5.8, 4. , 1.2],\n",
       "       [5. , 3.3, 1. ],\n",
       "       [5.6, 4.2, 1.3],\n",
       "       [5.7, 4.2, 1.2],\n",
       "       [5.7, 4.2, 1.3],\n",
       "       [6.2, 4.3, 1.3],\n",
       "       [5.1, 3. , 1.1],\n",
       "       [5.7, 4.1, 1.3],\n",
       "       [6.3, 6. , 2.5],\n",
       "       [5.8, 5.1, 1.9],\n",
       "       [7.1, 5.9, 2.1],\n",
       "       [6.3, 5.6, 1.8],\n",
       "       [6.5, 5.8, 2.2],\n",
       "       [7.6, 6.6, 2.1],\n",
       "       [4.9, 4.5, 1.7],\n",
       "       [7.3, 6.3, 1.8],\n",
       "       [6.7, 5.8, 1.8],\n",
       "       [7.2, 6.1, 2.5],\n",
       "       [6.5, 5.1, 2. ],\n",
       "       [6.4, 5.3, 1.9],\n",
       "       [6.8, 5.5, 2.1],\n",
       "       [5.7, 5. , 2. ],\n",
       "       [5.8, 5.1, 2.4],\n",
       "       [6.4, 5.3, 2.3],\n",
       "       [6.5, 5.5, 1.8],\n",
       "       [7.7, 6.7, 2.2],\n",
       "       [7.7, 6.9, 2.3],\n",
       "       [6. , 5. , 1.5],\n",
       "       [6.9, 5.7, 2.3],\n",
       "       [5.6, 4.9, 2. ],\n",
       "       [7.7, 6.7, 2. ],\n",
       "       [6.3, 4.9, 1.8],\n",
       "       [6.7, 5.7, 2.1],\n",
       "       [7.2, 6. , 1.8],\n",
       "       [6.2, 4.8, 1.8],\n",
       "       [6.1, 4.9, 1.8],\n",
       "       [6.4, 5.6, 2.1],\n",
       "       [7.2, 5.8, 1.6],\n",
       "       [7.4, 6.1, 1.9],\n",
       "       [7.9, 6.4, 2. ],\n",
       "       [6.4, 5.6, 2.2],\n",
       "       [6.3, 5.1, 1.5],\n",
       "       [6.1, 5.6, 1.4],\n",
       "       [7.7, 6.1, 2.3],\n",
       "       [6.3, 5.6, 2.4],\n",
       "       [6.4, 5.5, 1.8],\n",
       "       [6. , 4.8, 1.8],\n",
       "       [6.9, 5.4, 2.1],\n",
       "       [6.7, 5.6, 2.4],\n",
       "       [6.9, 5.1, 2.3],\n",
       "       [5.8, 5.1, 1.9],\n",
       "       [6.8, 5.9, 2.3],\n",
       "       [6.7, 5.7, 2.5],\n",
       "       [6.7, 5.2, 2.3],\n",
       "       [6.3, 5. , 1.9],\n",
       "       [6.5, 5.2, 2. ],\n",
       "       [6.2, 5.4, 2.3],\n",
       "       [5.9, 5.1, 1.8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#方差选择法，返回值为特征选择后的数据\n",
    "#参数threshold为方差的阈值\n",
    "VarianceThreshold(threshold=0.5).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter-2.卡方检验法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2],\n",
       "       [4.6, 1.5, 0.2],\n",
       "       [5. , 1.4, 0.2],\n",
       "       [5.4, 1.7, 0.4],\n",
       "       [4.6, 1.4, 0.3],\n",
       "       [5. , 1.5, 0.2],\n",
       "       [4.4, 1.4, 0.2],\n",
       "       [4.9, 1.5, 0.1],\n",
       "       [5.4, 1.5, 0.2],\n",
       "       [4.8, 1.6, 0.2],\n",
       "       [4.8, 1.4, 0.1],\n",
       "       [4.3, 1.1, 0.1],\n",
       "       [5.8, 1.2, 0.2],\n",
       "       [5.7, 1.5, 0.4],\n",
       "       [5.4, 1.3, 0.4],\n",
       "       [5.1, 1.4, 0.3],\n",
       "       [5.7, 1.7, 0.3],\n",
       "       [5.1, 1.5, 0.3],\n",
       "       [5.4, 1.7, 0.2],\n",
       "       [5.1, 1.5, 0.4],\n",
       "       [4.6, 1. , 0.2],\n",
       "       [5.1, 1.7, 0.5],\n",
       "       [4.8, 1.9, 0.2],\n",
       "       [5. , 1.6, 0.2],\n",
       "       [5. , 1.6, 0.4],\n",
       "       [5.2, 1.5, 0.2],\n",
       "       [5.2, 1.4, 0.2],\n",
       "       [4.7, 1.6, 0.2],\n",
       "       [4.8, 1.6, 0.2],\n",
       "       [5.4, 1.5, 0.4],\n",
       "       [5.2, 1.5, 0.1],\n",
       "       [5.5, 1.4, 0.2],\n",
       "       [4.9, 1.5, 0.2],\n",
       "       [5. , 1.2, 0.2],\n",
       "       [5.5, 1.3, 0.2],\n",
       "       [4.9, 1.4, 0.1],\n",
       "       [4.4, 1.3, 0.2],\n",
       "       [5.1, 1.5, 0.2],\n",
       "       [5. , 1.3, 0.3],\n",
       "       [4.5, 1.3, 0.3],\n",
       "       [4.4, 1.3, 0.2],\n",
       "       [5. , 1.6, 0.6],\n",
       "       [5.1, 1.9, 0.4],\n",
       "       [4.8, 1.4, 0.3],\n",
       "       [5.1, 1.6, 0.2],\n",
       "       [4.6, 1.4, 0.2],\n",
       "       [5.3, 1.5, 0.2],\n",
       "       [5. , 1.4, 0.2],\n",
       "       [7. , 4.7, 1.4],\n",
       "       [6.4, 4.5, 1.5],\n",
       "       [6.9, 4.9, 1.5],\n",
       "       [5.5, 4. , 1.3],\n",
       "       [6.5, 4.6, 1.5],\n",
       "       [5.7, 4.5, 1.3],\n",
       "       [6.3, 4.7, 1.6],\n",
       "       [4.9, 3.3, 1. ],\n",
       "       [6.6, 4.6, 1.3],\n",
       "       [5.2, 3.9, 1.4],\n",
       "       [5. , 3.5, 1. ],\n",
       "       [5.9, 4.2, 1.5],\n",
       "       [6. , 4. , 1. ],\n",
       "       [6.1, 4.7, 1.4],\n",
       "       [5.6, 3.6, 1.3],\n",
       "       [6.7, 4.4, 1.4],\n",
       "       [5.6, 4.5, 1.5],\n",
       "       [5.8, 4.1, 1. ],\n",
       "       [6.2, 4.5, 1.5],\n",
       "       [5.6, 3.9, 1.1],\n",
       "       [5.9, 4.8, 1.8],\n",
       "       [6.1, 4. , 1.3],\n",
       "       [6.3, 4.9, 1.5],\n",
       "       [6.1, 4.7, 1.2],\n",
       "       [6.4, 4.3, 1.3],\n",
       "       [6.6, 4.4, 1.4],\n",
       "       [6.8, 4.8, 1.4],\n",
       "       [6.7, 5. , 1.7],\n",
       "       [6. , 4.5, 1.5],\n",
       "       [5.7, 3.5, 1. ],\n",
       "       [5.5, 3.8, 1.1],\n",
       "       [5.5, 3.7, 1. ],\n",
       "       [5.8, 3.9, 1.2],\n",
       "       [6. , 5.1, 1.6],\n",
       "       [5.4, 4.5, 1.5],\n",
       "       [6. , 4.5, 1.6],\n",
       "       [6.7, 4.7, 1.5],\n",
       "       [6.3, 4.4, 1.3],\n",
       "       [5.6, 4.1, 1.3],\n",
       "       [5.5, 4. , 1.3],\n",
       "       [5.5, 4.4, 1.2],\n",
       "       [6.1, 4.6, 1.4],\n",
       "       [5.8, 4. , 1.2],\n",
       "       [5. , 3.3, 1. ],\n",
       "       [5.6, 4.2, 1.3],\n",
       "       [5.7, 4.2, 1.2],\n",
       "       [5.7, 4.2, 1.3],\n",
       "       [6.2, 4.3, 1.3],\n",
       "       [5.1, 3. , 1.1],\n",
       "       [5.7, 4.1, 1.3],\n",
       "       [6.3, 6. , 2.5],\n",
       "       [5.8, 5.1, 1.9],\n",
       "       [7.1, 5.9, 2.1],\n",
       "       [6.3, 5.6, 1.8],\n",
       "       [6.5, 5.8, 2.2],\n",
       "       [7.6, 6.6, 2.1],\n",
       "       [4.9, 4.5, 1.7],\n",
       "       [7.3, 6.3, 1.8],\n",
       "       [6.7, 5.8, 1.8],\n",
       "       [7.2, 6.1, 2.5],\n",
       "       [6.5, 5.1, 2. ],\n",
       "       [6.4, 5.3, 1.9],\n",
       "       [6.8, 5.5, 2.1],\n",
       "       [5.7, 5. , 2. ],\n",
       "       [5.8, 5.1, 2.4],\n",
       "       [6.4, 5.3, 2.3],\n",
       "       [6.5, 5.5, 1.8],\n",
       "       [7.7, 6.7, 2.2],\n",
       "       [7.7, 6.9, 2.3],\n",
       "       [6. , 5. , 1.5],\n",
       "       [6.9, 5.7, 2.3],\n",
       "       [5.6, 4.9, 2. ],\n",
       "       [7.7, 6.7, 2. ],\n",
       "       [6.3, 4.9, 1.8],\n",
       "       [6.7, 5.7, 2.1],\n",
       "       [7.2, 6. , 1.8],\n",
       "       [6.2, 4.8, 1.8],\n",
       "       [6.1, 4.9, 1.8],\n",
       "       [6.4, 5.6, 2.1],\n",
       "       [7.2, 5.8, 1.6],\n",
       "       [7.4, 6.1, 1.9],\n",
       "       [7.9, 6.4, 2. ],\n",
       "       [6.4, 5.6, 2.2],\n",
       "       [6.3, 5.1, 1.5],\n",
       "       [6.1, 5.6, 1.4],\n",
       "       [7.7, 6.1, 2.3],\n",
       "       [6.3, 5.6, 2.4],\n",
       "       [6.4, 5.5, 1.8],\n",
       "       [6. , 4.8, 1.8],\n",
       "       [6.9, 5.4, 2.1],\n",
       "       [6.7, 5.6, 2.4],\n",
       "       [6.9, 5.1, 2.3],\n",
       "       [5.8, 5.1, 1.9],\n",
       "       [6.8, 5.9, 2.3],\n",
       "       [6.7, 5.7, 2.5],\n",
       "       [6.7, 5.2, 2.3],\n",
       "       [6.3, 5. , 1.9],\n",
       "       [6.5, 5.2, 2. ],\n",
       "       [6.2, 5.4, 2.3],\n",
       "       [5.9, 5.1, 1.8]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检验自变量对因变量的相关性\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#选择K个最好的特征，返回选择特征后的数据\n",
    "SelectKBest(chi2, k=3).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 递归特征消除法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.5, 0.2],\n",
       "       [3. , 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.6, 0.2],\n",
       "       [3.9, 0.4],\n",
       "       [3.4, 0.3],\n",
       "       [3.4, 0.2],\n",
       "       [2.9, 0.2],\n",
       "       [3.1, 0.1],\n",
       "       [3.7, 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3. , 0.1],\n",
       "       [3. , 0.1],\n",
       "       [4. , 0.2],\n",
       "       [4.4, 0.4],\n",
       "       [3.9, 0.4],\n",
       "       [3.5, 0.3],\n",
       "       [3.8, 0.3],\n",
       "       [3.8, 0.3],\n",
       "       [3.4, 0.2],\n",
       "       [3.7, 0.4],\n",
       "       [3.6, 0.2],\n",
       "       [3.3, 0.5],\n",
       "       [3.4, 0.2],\n",
       "       [3. , 0.2],\n",
       "       [3.4, 0.4],\n",
       "       [3.5, 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.4, 0.4],\n",
       "       [4.1, 0.1],\n",
       "       [4.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.5, 0.2],\n",
       "       [3.6, 0.1],\n",
       "       [3. , 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3.5, 0.3],\n",
       "       [2.3, 0.3],\n",
       "       [3.2, 0.2],\n",
       "       [3.5, 0.6],\n",
       "       [3.8, 0.4],\n",
       "       [3. , 0.3],\n",
       "       [3.8, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.7, 0.2],\n",
       "       [3.3, 0.2],\n",
       "       [3.2, 1.4],\n",
       "       [3.2, 1.5],\n",
       "       [3.1, 1.5],\n",
       "       [2.3, 1.3],\n",
       "       [2.8, 1.5],\n",
       "       [2.8, 1.3],\n",
       "       [3.3, 1.6],\n",
       "       [2.4, 1. ],\n",
       "       [2.9, 1.3],\n",
       "       [2.7, 1.4],\n",
       "       [2. , 1. ],\n",
       "       [3. , 1.5],\n",
       "       [2.2, 1. ],\n",
       "       [2.9, 1.4],\n",
       "       [2.9, 1.3],\n",
       "       [3.1, 1.4],\n",
       "       [3. , 1.5],\n",
       "       [2.7, 1. ],\n",
       "       [2.2, 1.5],\n",
       "       [2.5, 1.1],\n",
       "       [3.2, 1.8],\n",
       "       [2.8, 1.3],\n",
       "       [2.5, 1.5],\n",
       "       [2.8, 1.2],\n",
       "       [2.9, 1.3],\n",
       "       [3. , 1.4],\n",
       "       [2.8, 1.4],\n",
       "       [3. , 1.7],\n",
       "       [2.9, 1.5],\n",
       "       [2.6, 1. ],\n",
       "       [2.4, 1.1],\n",
       "       [2.4, 1. ],\n",
       "       [2.7, 1.2],\n",
       "       [2.7, 1.6],\n",
       "       [3. , 1.5],\n",
       "       [3.4, 1.6],\n",
       "       [3.1, 1.5],\n",
       "       [2.3, 1.3],\n",
       "       [3. , 1.3],\n",
       "       [2.5, 1.3],\n",
       "       [2.6, 1.2],\n",
       "       [3. , 1.4],\n",
       "       [2.6, 1.2],\n",
       "       [2.3, 1. ],\n",
       "       [2.7, 1.3],\n",
       "       [3. , 1.2],\n",
       "       [2.9, 1.3],\n",
       "       [2.9, 1.3],\n",
       "       [2.5, 1.1],\n",
       "       [2.8, 1.3],\n",
       "       [3.3, 2.5],\n",
       "       [2.7, 1.9],\n",
       "       [3. , 2.1],\n",
       "       [2.9, 1.8],\n",
       "       [3. , 2.2],\n",
       "       [3. , 2.1],\n",
       "       [2.5, 1.7],\n",
       "       [2.9, 1.8],\n",
       "       [2.5, 1.8],\n",
       "       [3.6, 2.5],\n",
       "       [3.2, 2. ],\n",
       "       [2.7, 1.9],\n",
       "       [3. , 2.1],\n",
       "       [2.5, 2. ],\n",
       "       [2.8, 2.4],\n",
       "       [3.2, 2.3],\n",
       "       [3. , 1.8],\n",
       "       [3.8, 2.2],\n",
       "       [2.6, 2.3],\n",
       "       [2.2, 1.5],\n",
       "       [3.2, 2.3],\n",
       "       [2.8, 2. ],\n",
       "       [2.8, 2. ],\n",
       "       [2.7, 1.8],\n",
       "       [3.3, 2.1],\n",
       "       [3.2, 1.8],\n",
       "       [2.8, 1.8],\n",
       "       [3. , 1.8],\n",
       "       [2.8, 2.1],\n",
       "       [3. , 1.6],\n",
       "       [2.8, 1.9],\n",
       "       [3.8, 2. ],\n",
       "       [2.8, 2.2],\n",
       "       [2.8, 1.5],\n",
       "       [2.6, 1.4],\n",
       "       [3. , 2.3],\n",
       "       [3.4, 2.4],\n",
       "       [3.1, 1.8],\n",
       "       [3. , 1.8],\n",
       "       [3.1, 2.1],\n",
       "       [3.1, 2.4],\n",
       "       [3.1, 2.3],\n",
       "       [2.7, 1.9],\n",
       "       [3.2, 2.3],\n",
       "       [3.3, 2.5],\n",
       "       [3. , 2.3],\n",
       "       [2.5, 1.9],\n",
       "       [3. , 2. ],\n",
       "       [3.4, 2.3],\n",
       "       [3. , 1.8]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#递归特征消除法，返回特征选择后的数据\n",
    "#参数estimator为基模型\n",
    "#参数n_features_to_select为选择的特征个数\n",
    "RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于惩罚项的特征选择法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\conda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4],\n",
       "       [4.9, 3. , 1.4],\n",
       "       [4.7, 3.2, 1.3],\n",
       "       [4.6, 3.1, 1.5],\n",
       "       [5. , 3.6, 1.4],\n",
       "       [5.4, 3.9, 1.7],\n",
       "       [4.6, 3.4, 1.4],\n",
       "       [5. , 3.4, 1.5],\n",
       "       [4.4, 2.9, 1.4],\n",
       "       [4.9, 3.1, 1.5],\n",
       "       [5.4, 3.7, 1.5],\n",
       "       [4.8, 3.4, 1.6],\n",
       "       [4.8, 3. , 1.4],\n",
       "       [4.3, 3. , 1.1],\n",
       "       [5.8, 4. , 1.2],\n",
       "       [5.7, 4.4, 1.5],\n",
       "       [5.4, 3.9, 1.3],\n",
       "       [5.1, 3.5, 1.4],\n",
       "       [5.7, 3.8, 1.7],\n",
       "       [5.1, 3.8, 1.5],\n",
       "       [5.4, 3.4, 1.7],\n",
       "       [5.1, 3.7, 1.5],\n",
       "       [4.6, 3.6, 1. ],\n",
       "       [5.1, 3.3, 1.7],\n",
       "       [4.8, 3.4, 1.9],\n",
       "       [5. , 3. , 1.6],\n",
       "       [5. , 3.4, 1.6],\n",
       "       [5.2, 3.5, 1.5],\n",
       "       [5.2, 3.4, 1.4],\n",
       "       [4.7, 3.2, 1.6],\n",
       "       [4.8, 3.1, 1.6],\n",
       "       [5.4, 3.4, 1.5],\n",
       "       [5.2, 4.1, 1.5],\n",
       "       [5.5, 4.2, 1.4],\n",
       "       [4.9, 3.1, 1.5],\n",
       "       [5. , 3.2, 1.2],\n",
       "       [5.5, 3.5, 1.3],\n",
       "       [4.9, 3.6, 1.4],\n",
       "       [4.4, 3. , 1.3],\n",
       "       [5.1, 3.4, 1.5],\n",
       "       [5. , 3.5, 1.3],\n",
       "       [4.5, 2.3, 1.3],\n",
       "       [4.4, 3.2, 1.3],\n",
       "       [5. , 3.5, 1.6],\n",
       "       [5.1, 3.8, 1.9],\n",
       "       [4.8, 3. , 1.4],\n",
       "       [5.1, 3.8, 1.6],\n",
       "       [4.6, 3.2, 1.4],\n",
       "       [5.3, 3.7, 1.5],\n",
       "       [5. , 3.3, 1.4],\n",
       "       [7. , 3.2, 4.7],\n",
       "       [6.4, 3.2, 4.5],\n",
       "       [6.9, 3.1, 4.9],\n",
       "       [5.5, 2.3, 4. ],\n",
       "       [6.5, 2.8, 4.6],\n",
       "       [5.7, 2.8, 4.5],\n",
       "       [6.3, 3.3, 4.7],\n",
       "       [4.9, 2.4, 3.3],\n",
       "       [6.6, 2.9, 4.6],\n",
       "       [5.2, 2.7, 3.9],\n",
       "       [5. , 2. , 3.5],\n",
       "       [5.9, 3. , 4.2],\n",
       "       [6. , 2.2, 4. ],\n",
       "       [6.1, 2.9, 4.7],\n",
       "       [5.6, 2.9, 3.6],\n",
       "       [6.7, 3.1, 4.4],\n",
       "       [5.6, 3. , 4.5],\n",
       "       [5.8, 2.7, 4.1],\n",
       "       [6.2, 2.2, 4.5],\n",
       "       [5.6, 2.5, 3.9],\n",
       "       [5.9, 3.2, 4.8],\n",
       "       [6.1, 2.8, 4. ],\n",
       "       [6.3, 2.5, 4.9],\n",
       "       [6.1, 2.8, 4.7],\n",
       "       [6.4, 2.9, 4.3],\n",
       "       [6.6, 3. , 4.4],\n",
       "       [6.8, 2.8, 4.8],\n",
       "       [6.7, 3. , 5. ],\n",
       "       [6. , 2.9, 4.5],\n",
       "       [5.7, 2.6, 3.5],\n",
       "       [5.5, 2.4, 3.8],\n",
       "       [5.5, 2.4, 3.7],\n",
       "       [5.8, 2.7, 3.9],\n",
       "       [6. , 2.7, 5.1],\n",
       "       [5.4, 3. , 4.5],\n",
       "       [6. , 3.4, 4.5],\n",
       "       [6.7, 3.1, 4.7],\n",
       "       [6.3, 2.3, 4.4],\n",
       "       [5.6, 3. , 4.1],\n",
       "       [5.5, 2.5, 4. ],\n",
       "       [5.5, 2.6, 4.4],\n",
       "       [6.1, 3. , 4.6],\n",
       "       [5.8, 2.6, 4. ],\n",
       "       [5. , 2.3, 3.3],\n",
       "       [5.6, 2.7, 4.2],\n",
       "       [5.7, 3. , 4.2],\n",
       "       [5.7, 2.9, 4.2],\n",
       "       [6.2, 2.9, 4.3],\n",
       "       [5.1, 2.5, 3. ],\n",
       "       [5.7, 2.8, 4.1],\n",
       "       [6.3, 3.3, 6. ],\n",
       "       [5.8, 2.7, 5.1],\n",
       "       [7.1, 3. , 5.9],\n",
       "       [6.3, 2.9, 5.6],\n",
       "       [6.5, 3. , 5.8],\n",
       "       [7.6, 3. , 6.6],\n",
       "       [4.9, 2.5, 4.5],\n",
       "       [7.3, 2.9, 6.3],\n",
       "       [6.7, 2.5, 5.8],\n",
       "       [7.2, 3.6, 6.1],\n",
       "       [6.5, 3.2, 5.1],\n",
       "       [6.4, 2.7, 5.3],\n",
       "       [6.8, 3. , 5.5],\n",
       "       [5.7, 2.5, 5. ],\n",
       "       [5.8, 2.8, 5.1],\n",
       "       [6.4, 3.2, 5.3],\n",
       "       [6.5, 3. , 5.5],\n",
       "       [7.7, 3.8, 6.7],\n",
       "       [7.7, 2.6, 6.9],\n",
       "       [6. , 2.2, 5. ],\n",
       "       [6.9, 3.2, 5.7],\n",
       "       [5.6, 2.8, 4.9],\n",
       "       [7.7, 2.8, 6.7],\n",
       "       [6.3, 2.7, 4.9],\n",
       "       [6.7, 3.3, 5.7],\n",
       "       [7.2, 3.2, 6. ],\n",
       "       [6.2, 2.8, 4.8],\n",
       "       [6.1, 3. , 4.9],\n",
       "       [6.4, 2.8, 5.6],\n",
       "       [7.2, 3. , 5.8],\n",
       "       [7.4, 2.8, 6.1],\n",
       "       [7.9, 3.8, 6.4],\n",
       "       [6.4, 2.8, 5.6],\n",
       "       [6.3, 2.8, 5.1],\n",
       "       [6.1, 2.6, 5.6],\n",
       "       [7.7, 3. , 6.1],\n",
       "       [6.3, 3.4, 5.6],\n",
       "       [6.4, 3.1, 5.5],\n",
       "       [6. , 3. , 4.8],\n",
       "       [6.9, 3.1, 5.4],\n",
       "       [6.7, 3.1, 5.6],\n",
       "       [6.9, 3.1, 5.1],\n",
       "       [5.8, 2.7, 5.1],\n",
       "       [6.8, 3.2, 5.9],\n",
       "       [6.7, 3.3, 5.7],\n",
       "       [6.7, 3. , 5.2],\n",
       "       [6.3, 2.5, 5. ],\n",
       "       [6.5, 3. , 5.2],\n",
       "       [6.2, 3.4, 5.4],\n",
       "       [5.9, 3. , 5.1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#带L1惩罚项的逻辑回归作为基模型的特征选择\n",
    "SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.1)).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
